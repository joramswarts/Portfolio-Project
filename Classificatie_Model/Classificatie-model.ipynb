{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from sklearn.base import is_classifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.storage.blob import BlobServiceClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure Blob Storage Configuratie\n",
    "STORAGE_ACCOUNT_NAME = \"bdtscraper\"\n",
    "CONTAINER_NAME = \"csv-files\"\n",
    "BLOB_FILES = [\"student-mat.csv\", \"student-por.csv\"]\n",
    "\n",
    "# Verbinden met Azure Blob Storage via DefaultAzureCredential\n",
    "def get_blob_service_client():\n",
    "    credential = DefaultAzureCredential()\n",
    "    return BlobServiceClient(\n",
    "        account_url=f\"https://{STORAGE_ACCOUNT_NAME}.blob.core.windows.net\", \n",
    "        credential=credential\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lees de datasets in vanuit Azure Blob Storage\n",
    "def load_data_from_blob(blob_name):\n",
    "    \"\"\"Laadt een CSV-bestand vanuit Azure Blob Storage in als een Pandas DataFrame.\"\"\"\n",
    "    blob_service_client = get_blob_service_client()\n",
    "    blob_client = blob_service_client.get_blob_client(container=CONTAINER_NAME, blob=blob_name)\n",
    "    \n",
    "    blob_data = blob_client.download_blob().readall().decode(\"utf-8\")\n",
    "    return pd.read_csv(StringIO(blob_data), sep=\";\")\n",
    "\n",
    "datasets = {name.split(\".\")[0]: load_data_from_blob(name) for name in BLOB_FILES}\n",
    "\n",
    "# Converteer de target naar een binaire classificatie\n",
    "for name, data in datasets.items():\n",
    "    data['G3_class'] = (data['G3'] >= 10).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "first_dataset = next(iter(datasets.values()))\n",
    "first_dummies = pd.get_dummies(first_dataset, drop_first=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    first_dummies.drop(columns=['G3', 'G3_class']),\n",
    "    first_dummies['G3_class'],\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelbeheer\n",
    "class Readwritemodel():\n",
    "    def __init__(self, model=None, filenaam=None):\n",
    "        self.filenaam = filenaam\n",
    "        self.model = model  \n",
    "    \n",
    "    def check_input(self, var):\n",
    "        return isinstance(var, str) and var.endswith(\".sav\")\n",
    "\n",
    "    def opslaanmodel(self):\n",
    "        if self.check_input(self.filenaam):\n",
    "            pickle.dump(self.model, open(self.filenaam, 'wb'))\n",
    "            print(f\"Jouw model is opgeslagen onder de naam: {self.filenaam}\")\n",
    "        \n",
    "    def inladenmodel(self):\n",
    "        if self.check_input(self.filenaam):\n",
    "            try:\n",
    "                geladen_model = pickle.load(open(self.filenaam, 'rb'))\n",
    "                if is_classifier(geladen_model):\n",
    "                    print(\"Jouw model is opgehaald en je kan er nu mee voorspellen!\")\n",
    "                    return geladen_model\n",
    "            except FileNotFoundError:\n",
    "                print(\"Het modelbestand kan niet gevonden worden. Er wordt een nieuw model getraind.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jouw model is opgehaald en je kan er nu mee voorspellen!\n",
      "Je gebruikt nu een opgeslagen model\n"
     ]
    }
   ],
   "source": [
    "# Modelbeheer\n",
    "func = Readwritemodel(filenaam=\"classificatie_model.sav\")\n",
    "model = func.inladenmodel()\n",
    "\n",
    "if model is None:\n",
    "    print(\"Ik train een model...\")\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    func.model = model\n",
    "    func.opslaanmodel()\n",
    "else:\n",
    "    print(\"Je gebruikt nu een opgeslagen model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verwerken van dataset: student-mat\n",
      "Voorspellingen opgeslagen in student-mat_classification_predictions.csv\n",
      "Verwerken van dataset: student-por\n",
      "Voorspellingen opgeslagen in student-por_classification_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# Loop door beide datasets en maak voorspellingen\n",
    "for name, data in datasets.items():\n",
    "    print(f\"Verwerken van dataset: {name}\")\n",
    "    data_dummies = pd.get_dummies(data, drop_first=True)\n",
    "    X = data_dummies.drop(columns=['G3', 'G3_class'])\n",
    "    \n",
    "    # Controleer of de kolommen overeenkomen met de trainingsdata\n",
    "    missing_cols = set(X_train.columns) - set(X.columns)\n",
    "    extra_cols = set(X.columns) - set(X_train.columns)\n",
    "    \n",
    "    for col in missing_cols:\n",
    "        X[col] = 0\n",
    "    \n",
    "    X = X[X_train.columns]\n",
    "    \n",
    "    y_pred = model.predict(X)\n",
    "    data['Predictions'] = y_pred\n",
    "    \n",
    "    output_filename = f\"{name}_classification_predictions.csv\"\n",
    "    data.to_csv(output_filename, sep=\";\", index=False)\n",
    "    print(f\"Voorspellingen opgeslagen in {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9240506329113924\n",
      "Confusion Matrix:\n",
      "[[25  2]\n",
      " [ 4 48]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.86      0.93      0.89        27\n",
      "        True       0.96      0.92      0.94        52\n",
      "\n",
      "    accuracy                           0.92        79\n",
      "   macro avg       0.91      0.92      0.92        79\n",
      "weighted avg       0.93      0.92      0.92        79\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluatie op de testset\n",
    "accuracy = accuracy_score(y_test, model.predict(X_test))\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, model.predict(X_test)))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, model.predict(X_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
